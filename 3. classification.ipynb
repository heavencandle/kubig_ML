{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Library\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SAMPLE_IDX = 36000\n",
    "TOTAL_SIZE = 0\n",
    "TRAIN_SIZE = 60000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(sample):\n",
    "    # show sample digit image w/ pyplot\n",
    "    sample_resize = sample.reshape(28, 28)\n",
    "\n",
    "    plt.imshow(sample_resize, cmap = matplotlib.cm.binary, interpolation= \"nearest\")\n",
    "    # cmap: color map / interpolation: whether to interpolate btw pixels if the display resolution is not the same as the image resolution\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784) (70000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# fetch mnist data\n",
    "mnist = fetch_openml('mnist_784')\n",
    "X, y = mnist['data'], mnist['target']\n",
    "TOTAL_SIZE = X.shape[0]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle and generate train, test set\n",
    "shuffle_idx = np.random.permutation(TOTAL_SIZE)\n",
    "X, y = X[shuffle_idx], y[shuffle_idx]\n",
    "X_train, y_train, X_test, y_test = X[:TRAIN_SIZE], y[:TRAIN_SIZE], X[TRAIN_SIZE:], y[TRAIN_SIZE:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show sample digit image w/ pyplot\n",
    "X_sample = X[SAMPLE_IDX]\n",
    "y_sample = y[SAMPLE_IDX]\n",
    "show_img(X_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-1. Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- binary classifier - 5 or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.linear_model import SGDClassifier # SGD Classifier: train instances one by one(online learning)\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.base import clone, BaseEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_5 = (y_train == '5')\n",
    "y_test_5 = (y_test == '5')\n",
    "\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "sgd_clf.fit(X_train, y_train_5)\n",
    "\n",
    "print(\"prediction:\", sgd_clf.predict([X_sample]))\n",
    "print(\"answer:\", y_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- measurement\n",
    "    - StratifiedKFold: performs stratified sampling to produce folds that contain a representative ratio of each class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measurement of binary classifier\n",
    "skfolds = StratifiedKFold(n_splits=3)\n",
    "\n",
    "# measurement 1 : stratifiedKFold\n",
    "for train_idx, check_idx in skfolds.split(X_train, y_train_5): \n",
    "    clone_clf = clone(sgd_clf) # create a clone of classifier\n",
    "    X_train_folds = X_train[train_idx]\n",
    "    y_train_fold = y_train_5[train_idx]\n",
    "    X_check_folds = X_train[check_idx]\n",
    "    y_check_fold = y_train_5[check_idx]\n",
    "\n",
    "    clone_clf.fit(X_train_folds, y_train_fold) # train the clone on the training folds\n",
    "    y_pred = clone_clf.predict(X_check_folds) # make predictions on the check(i.e. the otehr 2 folds) fold\n",
    "    n_correct = sum(y_pred == y_check_fold)\n",
    "    print(n_correct/ len(y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measurement 2 : cross_val_score\n",
    "print(cross_val_score(sgd_clf, X_train, y_train_5, cv = 3, scoring = \"accuracy\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measurement 3 : compare with dumb classifier\n",
    "class Never5Classifier(BaseEstimator):\n",
    "    def fit(self, X, y=None): pass\n",
    "    def predict(self, X): return np.zeros((len(X), 1), dtype = bool)\n",
    "\n",
    "never_5_clf = Never5Classifier()\n",
    "print(cross_val_score(never_5_clf, X_train, y_train_5, cv =3, scoring=\"accuracy\")) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-2. Multiclass Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- OvA; One-versus-All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scikit-learn automatically runs OvA\n",
    "sgd_clf.fit(X_train, y_train)\n",
    "sgd_clf.predict([X[SAMPLE_IDX]])\n",
    "\n",
    "sample_scores = sgd_clf.decision_function([X[SAMPLE_IDX]])\n",
    "sample_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx, predicting = np.argmax(sample_scores), sgd_clf.classes_[idx]\n",
    "idx, predicting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- OvO; One-versus-one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "ovo_clf = OneVsOneClassifier(SGDClassifier(random_state=42))\n",
    "ovo_clf.fit(X_train, y_train)\n",
    "ovo_clf.predict([X_sample])\n",
    "\n",
    "# print(len(ovo_clf.estimators_), '\\n',ovo_clf.estimators_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_clf.fit(X_train, y_train)\n",
    "forest_clf.predict([X_sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_clf.predict_proba([X_sample]) \n",
    "\n",
    "'''\n",
    "predict_proba():\n",
    "   returns an array contatining a row per instance and a column per class, \n",
    "   each containing the probability that the given instance belongs to the given class\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(sgd_clf, X_train, y_train, cv=3, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-3. Multilabel Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "y_train = np.array(list(map(int, y_train)))\n",
    "y_train_large = (y_train>=7)\n",
    "y_train_odd=(y_train%2==1)\n",
    "y_multilabel = np.c_[y_train_large, y_train_odd] #np.c_ : column 방향으로 데이터 추가\n",
    "\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(X_train, y_multilabel)\n",
    "knn_clf.predict([X[SAMPLE_IDX]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_knn_pred = cross_val_predict(knn_clf, X_train, y_train, cv=3)\n",
    "f1_macro = f1_score(y_train, y_train_knn_pred, average=\"macro\")\n",
    "f1_weighted = f1_score(y_train, y_train_knn_pred, average=\"weighted\") # give more weight to the classifier's score depending on its support(i.e. the number of instances with that target label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_weighted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-4. Multioutput Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ": generalization of multilabel classification, each label can be multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of noise\n",
    "noise =np.random.randint(0, 100, (len(X_train), 784))\n",
    "X_train_mod = X_train + noise\n",
    "noise =np.random.randint(0, 100, (len(test), 784))\n",
    "X_test_mod = X_test + noise\n",
    "y_train_mod = X_train\n",
    "y_test_mod = X_test\n",
    "\n",
    "knn_clf.fit(X_train_mod, y_train_mod)\n",
    "clean_digit = knn.clf.predict([X_test_mod[SAMPLE_IDX]])\n",
    "\n",
    "\n",
    "show_img(clean_digit[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-5. Measuring Accuracy - using cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Confuion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- confusion matrix\n",
    "    - row: actual class\n",
    "    - column: predicted class\n",
    "    - best case: nonzero values only on its main diagonal\n",
    "    \n",
    "    \n",
    "- precision / recall\n",
    "![alt text](https://hugrypiggykim.com/wp-content/uploads/2018/05/B04223_10_02.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)\n",
    "confusion_matrix(y_train_5, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "precision = precision_score(y_train_5, y_train_pred)\n",
    "recall = recall_score(y_train_5, y_train_pred)\n",
    "\n",
    "precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision_function: returns score for each instance\n",
    "y_scores = sgd_clf.decision_function([X_train[SAMPLE_IDX]])\n",
    "threshold = 0\n",
    "y_sample_digit_pred = (y_scores > threshold)\n",
    "y_sample_digit_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns predicted labels\n",
    "# y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3) \n",
    "\n",
    "#return decision scores instead of predictions\n",
    "y_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3, method = \"decision_function\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Precision-Recall Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- precision / recall tradeoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)\n",
    "\n",
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
    "    plt.plot(thresholds, precisions[:-1], \"b--\", label = \"Precision\")\n",
    "    plt.plot(thresholds, recalls[:-1], \"g-\", label = \"Recall\")\n",
    "    plt.xlabel(\"Threshold\")\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.ylim([0,1])\n",
    "    \n",
    "plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_vs_recall(precisions, recalls):\n",
    "    plt.plot(recalls[:-1], precisions[:-1], \"b-\")\n",
    "    plt.xlabel(\"recall\")\n",
    "    plt.ylabel(\"precision\")\n",
    "    plt.xlim([0,1])\n",
    "    plt.ylim([0,1])\n",
    "    plt.show()\n",
    "\n",
    "plot_precision_vs_recall(precisions, recalls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) ROC curve; Receiver Operating Chracteristic curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- x: false positive rate, y: true positive rate(=recall)\n",
    "- the higher the recall(TPR), the more false positives(FPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(y_train_5, y_scores)\n",
    "\n",
    "def plot_roc_curve(fpr, tpr, label=None):\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
    "    plt.plot([0,1], [0,1], 'k--')\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Posive Rate')\n",
    "    \n",
    "plot_roc_curve(fpr, tpr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- AUC;Area Under the Curve\n",
    "    - is used to compare classifiers\n",
    "    - best = AUC equals to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_train_5, y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest_clf = RandomForestClassifier(random_state=42)\n",
    "y_probas_forest = cross_val_predict(forest_clf, X_train,y_train_5, cv=3, method=\"predict_proba\")\n",
    "\n",
    "y_scores_forest = y_probas_forest[:, 1] #score = proba of positive class\n",
    "fpr_forest, tpr_forest, thresholds_forest = roc_curve(y_train_5, y_scores_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr, tpr, \"b:\", label=\"SGD\")\n",
    "plot_roc_curve(fpr_forest, tpr_forest, \"Random Forest\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_train_5, y_scores_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **precision/recall curve or ROC curve?**  \n",
    "-PR curve: whenever the positive class is rare or when care more about the false positives than the false negatives  \n",
    "-ROC curve: otherwise  \n",
    "\n",
    "\n",
    ">e.g. 5-or-not model may seems to have good ROC curve, but its because there are only a few positives(5s) compared to the negatives (non-5s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-5. Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.astype(np.float64))\n",
    "cross_val_score(sgd_clf, X_train_scaled, y_train, cv=3, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = cross_val_predict(sgd_clf, X_train_scaled, y_train, cv=3)\n",
    "conf_mx = confusion_matrix(y_train, y_train_pred)\n",
    "conf_mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(conf_mx, cmap=plt.cm.gray) #Display an array as a matrix in a new figure window.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_sums = conf_mx.sum(axis=1, keepdims=True)\n",
    "norm_conf_mx = conf_mx/row_sums\n",
    "np.fill_diagonal(norm_conf_mx, 0)\n",
    "plt.matshow(norm_conf_mx, cmap=plt.cm.gray) # row: actual class, column: predicted class\n",
    "plt.show() # element with white represents confusing pairs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
